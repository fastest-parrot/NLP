{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SKENNEDY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SKENNEDY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import requests\n",
    "from nltk import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown as md\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "import regex as re\n",
    "import numpy as np\n",
    "from nltk.metrics import edit_distance\n",
    "from nltk.metrics.distance import jaro_similarity, presence\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)\n",
    "\n",
    "def scale(array, scale_type='standard'):\n",
    "    if scale_type == 'standard': #mean zero, std = 1\n",
    "        return (array - np.mean(array))/np.std(array)\n",
    "    if scale_type == 'min_max':\n",
    "        return (array - np.min(array))/(np.max(array) - np.min(array))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text_sub = re.sub('[^A-Za-z0-9]+', ' ', text)\n",
    "    display(md(f'{text_sub[:100]}'))\n",
    "    tokens = word_tokenize(text_sub)\n",
    "    display(md(f'*Raw tokens found: {len(tokens):,.0f}*'))\n",
    "    display(md(f'*Raw Vocab Size: {len(set(tokens)):,.0f}*'))\n",
    "    nltk_text = nltk.Text(tokens)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_text = ' '.join(\n",
    "        [w for w in nltk_text if not w in stop_words])\n",
    "    tokens_filtered = word_tokenize(filtered_text)\n",
    "    nltk_text_filtered = nltk.Text(tokens_filtered)\n",
    "    return nltk_text_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Run one of the part-of-speech (POS) taggers available in Python.*** \n",
    "\n",
    "- Find the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sean, slim = 'sean' , 'slim'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. Explain your conjecture as to why the tagger might have been less than perfect with this sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance(sean, slim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaro_similarity(sean, slim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'s'}, {'a', 'e', 'n'})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(sean).intersection(set(slim)), set(sean).difference(set(slim)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***My grandma loves the bible :)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = \"In the beginning God created the heaven and the earth. And the earth was without form, and void; and darkness was upon the face of the deep.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "in the beginning god created the heaven and the earth and the earth was without form and void and da"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Raw tokens found: 27*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Raw Vocab Size: 17*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean = clean_text(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beginning',\n",
       " 'god',\n",
       " 'created',\n",
       " 'heaven',\n",
       " 'earth',\n",
       " 'earth',\n",
       " 'without',\n",
       " 'form',\n",
       " 'void',\n",
       " 'darkness',\n",
       " 'upon',\n",
       " 'face',\n",
       " 'deep']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***She still knows its the bible - this is a iconic line from a book that has been around for the better part of 2,000 years. Even if she wasn't devout, there are plenty of contextual clues that could lead someone to guess that this is a religious text, at the very least.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'the',\n",
       " 'begin',\n",
       " 'god',\n",
       " 'creat',\n",
       " 'the',\n",
       " 'heaven',\n",
       " 'and',\n",
       " 'the',\n",
       " 'earth.',\n",
       " 'and',\n",
       " 'the',\n",
       " 'earth',\n",
       " 'wa',\n",
       " 'without',\n",
       " 'form,',\n",
       " 'and',\n",
       " 'void;',\n",
       " 'and',\n",
       " 'dark',\n",
       " 'wa',\n",
       " 'upon',\n",
       " 'the',\n",
       " 'face',\n",
       " 'of',\n",
       " 'the',\n",
       " 'deep.']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "[stemmer.stem(x) for x in book.split(' ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The PorterStemmer incorrectly truncates two of the 27 words (created and was). 92.6 % of the words remained valid after transform.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'the',\n",
       " 'begin',\n",
       " 'god',\n",
       " 'creat',\n",
       " 'the',\n",
       " 'heaven',\n",
       " 'and',\n",
       " 'the',\n",
       " 'earth.',\n",
       " 'and',\n",
       " 'the',\n",
       " 'earth',\n",
       " 'was',\n",
       " 'without',\n",
       " 'form,',\n",
       " 'and',\n",
       " 'void;',\n",
       " 'and',\n",
       " 'dark',\n",
       " 'was',\n",
       " 'upon',\n",
       " 'the',\n",
       " 'face',\n",
       " 'of',\n",
       " 'the',\n",
       " 'deep.']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "[stemmer.stem(x) for x in book.split(' ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The SnowballStemmer incorrectly truncates one of the 27 words (created). 96.3 % of the words remained valid after transform.***"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
